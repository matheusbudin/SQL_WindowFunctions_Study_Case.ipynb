{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Study Case: Analyzing Sales Data\n",
        "\n",
        "Imagine you're working with a dataset of sales transactions, and you want to perform various analytical tasks using Spark SQL, including calculating running totals, ranking products by sales, and summarizing sales by different categories."
      ],
      "metadata": {
        "id": "dSs51DRM6RkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wpapc7oX1AGh",
        "outputId": "33cd9348-9c45-4059-a11e-1902dbe04eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=c246619f32b59552e27b483821ec84e68348188c0057ba2a94075ccdbb9c9fac\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Example DataFrames:\n",
        "We will create two DataFrames `salesDF` and `productsDF`, to represent sales transactions and product information."
      ],
      "metadata": {
        "id": "DFIFlsZc6f-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"SparkSQLExample\").getOrCreate()\n",
        "\n",
        "\n",
        "# Sample data for sales transactions:\n",
        "\n",
        "sales_data = [\n",
        "    Row(transaction_id=1, product_id=101, sale_date = '2023-01-01', quantity = 3, price = 50.0),\n",
        "    Row(transaction_id=2, product_id=102, sale_date = '2023-01-02', quantity = 2, price=30.0),\n",
        "    Row(transaction_id=3, product_id=101, sale_date='2023-01-03', quantity=4, price=60.0),\n",
        "    Row(transaction_id=4, product_id=103, sale_date='2023-01-04', quantity=5, price=25.0),\n",
        "    Row(transaction_id=5, product_id=104, sale_date='2023-01-05', quantity=2, price=40.0),\n",
        "    Row(transaction_id=6, product_id=102, sale_date='2023-01-06', quantity=3, price=30.0),\n",
        "    Row(transaction_id=7, product_id=104, sale_date='2023-01-07', quantity=1, price=40.0),\n",
        "    Row(transaction_id=8, product_id=105, sale_date='2023-01-08', quantity=2, price=50.0),\n",
        "    Row(transaction_id=9, product_id=101, sale_date='2023-01-09', quantity=3, price=60.0),\n",
        "    Row(transaction_id=10, product_id=102, sale_date='2023-01-10', quantity=4, price=30.0),\n",
        "    Row(transaction_id=11, product_id=103, sale_date='2023-01-11', quantity=2, price=25.0),\n",
        "    Row(transaction_id=12, product_id=104, sale_date='2023-01-12', quantity=1, price=40.0),\n",
        "    Row(transaction_id=13, product_id=105, sale_date='2023-01-13', quantity=5, price=50.0),\n",
        "    Row(transaction_id=14, product_id=101, sale_date='2023-01-14', quantity=2, price=60.0),\n",
        "    Row(transaction_id=15, product_id=102, sale_date='2023-01-15', quantity=3, price=30.0),\n",
        "    Row(transaction_id=16, product_id=103, sale_date='2023-01-16', quantity=1, price=25.0),\n",
        "]\n",
        "\n",
        "\n",
        "products_data = [\n",
        "    Row(product_id=101, product_category='Electronics'),\n",
        "    Row(product_id=102, product_category='Clothing'),\n",
        "    Row(product_id=103, product_category='Electronics'),\n",
        "    Row(product_id=104, product_category='Clothing'),\n",
        "    Row(product_id=105, product_category='Electronics'),\n",
        "    Row(product_id=106, product_category='Books'),\n",
        "    Row(product_id=107, product_category='Books'),\n",
        "    Row(product_id=108, product_category='Clothing'),\n",
        "    Row(product_id=109, product_category='Electronics'),\n",
        "    Row(product_id=110, product_category='Electronics'),\n",
        "    Row(product_id=111, product_category='Books'),\n",
        "    Row(product_id=112, product_category='Clothing'),\n",
        "    Row(product_id=113, product_category='Books'),\n",
        "    Row(product_id=114, product_category='Books'),\n",
        "    Row(product_id=115, product_category='Clothing'),\n",
        "    Row(product_id=116, product_category='Clothing'),\n",
        "    Row(product_id=117, product_category='Electronics'),\n",
        "    Row(product_id=118, product_category='Books'),\n",
        "    Row(product_id=119, product_category='Books'),\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "YlHaVjOm6cJV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the Schema for each data frame:\n",
        "\n",
        "sales_schema = StructType([\n",
        "    StructField(\"transaction_id\", IntegerType(), True),\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"sale_date\", StringType(), True),\n",
        "    StructField(\"quantity\", IntegerType(), True),\n",
        "    StructField(\"price\", FloatType(), True),\n",
        "])\n",
        "\n",
        "products_schema = StructType([\n",
        "    StructField(\"product_id\", IntegerType(), True),\n",
        "    StructField(\"product_category\", StringType(), True),\n",
        "])"
      ],
      "metadata": {
        "id": "c_qY4ttR8Jwy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames\n",
        "salesDF = spark.createDataFrame(sales_data, sales_schema)\n",
        "productsDF = spark.createDataFrame(products_data, products_schema)\n",
        "\n",
        "\n",
        "# Convert date strings to DateType using to_date function\n",
        "sales_data = [Row(transaction_id=row.transaction_id,\n",
        "                   product_id=row.product_id,\n",
        "                   sale_date=to_date(row.sale_date, 'yyyy-MM-dd'),\n",
        "                   quantity=row.quantity,\n",
        "                   price=row.price)\n",
        "              for row in sales_data]\n",
        "\n",
        "\n",
        "# Register DataFrames as temporary SQL tables\n",
        "salesDF.createOrReplaceTempView(\"sales\")\n",
        "productsDF.createOrReplaceTempView(\"products\")"
      ],
      "metadata": {
        "id": "jvKEDT1T8USr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verifying the schema for each dataframe\n",
        "\n",
        "salesDF = salesDF.withColumn(\"sale_date\", to_date(\"sale_date\", 'yyyy-MM-dd'))\n",
        "\n",
        "salesDF.printSchema()\n",
        "\n",
        "print()\n",
        "\n",
        "productsDF.printSchema()\n",
        "\n",
        "salesDF.createOrReplaceTempView(\"sales\")\n",
        "productsDF.createOrReplaceTempView(\"products\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRhSbGCE9g-9",
        "outputId": "bf0bee78-e12c-445a-c503-f91fd0e12e8e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- transaction_id: integer (nullable = true)\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- sale_date: date (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- price: float (nullable = true)\n",
            "\n",
            "\n",
            "root\n",
            " |-- product_id: integer (nullable = true)\n",
            " |-- product_category: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nme0W_Oa-Fqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example 1: Calculating the Running Total\n",
        "\n",
        "In this example, we use a window function to calculate the running total of sales for each transaction."
      ],
      "metadata": {
        "id": "PAgRpyx3-LM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "totalDF = spark.sql(\"\"\"\n",
        "\n",
        "  SELECT\n",
        "      transaction_id,\n",
        "      product_id,\n",
        "      sale_date,\n",
        "      quantity,\n",
        "      price,\n",
        "      SUM(price * quantity) OVER (PARTITION BY transaction_id ORDER BY sale_date) AS running_total\n",
        "\n",
        "  FROM sales\n",
        "\n",
        "\n",
        "\n",
        "\"\"\")\n",
        "totalDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag3ohJ_U-OZm",
        "outputId": "92151e06-b8a9-40df-bc87-503d63f46e86"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+----------+--------+-----+-------------+\n",
            "|transaction_id|product_id|sale_date |quantity|price|running_total|\n",
            "+--------------+----------+----------+--------+-----+-------------+\n",
            "|1             |101       |2023-01-01|3       |50.0 |150.0        |\n",
            "|2             |102       |2023-01-02|2       |30.0 |60.0         |\n",
            "|3             |101       |2023-01-03|4       |60.0 |240.0        |\n",
            "|4             |103       |2023-01-04|5       |25.0 |125.0        |\n",
            "|5             |104       |2023-01-05|2       |40.0 |80.0         |\n",
            "|6             |102       |2023-01-06|3       |30.0 |90.0         |\n",
            "|7             |104       |2023-01-07|1       |40.0 |40.0         |\n",
            "|8             |105       |2023-01-08|2       |50.0 |100.0        |\n",
            "|9             |101       |2023-01-09|3       |60.0 |180.0        |\n",
            "|10            |102       |2023-01-10|4       |30.0 |120.0        |\n",
            "|11            |103       |2023-01-11|2       |25.0 |50.0         |\n",
            "|12            |104       |2023-01-12|1       |40.0 |40.0         |\n",
            "|13            |105       |2023-01-13|5       |50.0 |250.0        |\n",
            "|14            |101       |2023-01-14|2       |60.0 |120.0        |\n",
            "|15            |102       |2023-01-15|3       |30.0 |90.0         |\n",
            "|16            |103       |2023-01-16|1       |25.0 |25.0         |\n",
            "+--------------+----------+----------+--------+-----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:\n",
        "\n",
        "The SUM(price * quantity) calculates the total sale amount for each transaction.\n",
        "The OVER clause defines the window frame for the window function.\n",
        "PARTITION BY transaction_id indicates that the window frame is partitioned by the transaction_id, meaning the calculation resets for each new transaction.\n",
        "ORDER BY sale_date specifies the order within the window frame, which ensures that the running total is calculated based on the chronological order of sale dates.\n",
        "The result includes columns for the transaction details, and the running_total column shows the cumulative sales amount for each transaction."
      ],
      "metadata": {
        "id": "d3UqrrzXFlyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Rank Products by Sale\n",
        "\n",
        "In this example, we use a window function to rank products by their total sales.\n"
      ],
      "metadata": {
        "id": "HmTy6xjHBGoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_ranked_products = spark.sql(\"\"\"\n",
        "\n",
        "    SELECT\n",
        "        product_id,\n",
        "        SUM(price * quantity) AS total_sales,\n",
        "        RANK() OVER (ORDER BY SUM(price * quantity) DESC) AS sales_rank\n",
        "\n",
        "    FROM sales\n",
        "\n",
        "    GROUP BY product_id\n",
        "\n",
        "\"\"\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgvJEa7l_-Bl",
        "outputId": "842c254f-267f-41fd-fc0f-3e1ae1073f52"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+----------+\n",
            "|product_id|total_sales|sales_rank|\n",
            "+----------+-----------+----------+\n",
            "|101       |690.0      |1         |\n",
            "|102       |360.0      |2         |\n",
            "|105       |350.0      |3         |\n",
            "|103       |200.0      |4         |\n",
            "|104       |160.0      |5         |\n",
            "+----------+-----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:\n",
        "\n",
        "The SUM(price * quantity) calculates the total sales amount for each product.\n",
        "The RANK() function is a window function that assigns a rank to each product based on the total sales.\n",
        "ORDER BY SUM(price * quantity) DESC orders the products by descending total sales, which means the product with the highest sales gets the lowest rank.\n",
        "The result shows the product_id, total_sales, and sales_rank columns, indicating the total sales for each product and its ranking."
      ],
      "metadata": {
        "id": "Fe1kY2CiFpif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example 3: Summarize Sales by Category\n",
        "\n",
        "In this example, we use window functions to summarize sales by product category."
      ],
      "metadata": {
        "id": "JV031mTdBzI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sales_by_category = spark.sql(\"\"\"\n",
        "\n",
        "    SELECT\n",
        "        p.product_id,\n",
        "        p.product_category,\n",
        "        SUM(s.price * s.quantity) As total_sales\n",
        "\n",
        "    FROM sales AS s\n",
        "    INNER JOIN products p ON s.product_id = p.product_id\n",
        "    GROUP BY p.product_id, p.product_category\n",
        "\n",
        "\"\"\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEAlhVHRByHA",
        "outputId": "774ca591-c493-4880-cfbf-6e27f72ce6aa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------+-----------+\n",
            "|product_id|product_category|total_sales|\n",
            "+----------+----------------+-----------+\n",
            "|101       |Electronics     |690.0      |\n",
            "|102       |Clothing        |360.0      |\n",
            "|103       |Electronics     |200.0      |\n",
            "|104       |Clothing        |160.0      |\n",
            "|105       |Electronics     |350.0      |\n",
            "+----------+----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:\n",
        "\n",
        "We're performing a join between the sales and products tables to get the product category information.\n",
        "The SUM(price * quantity) calculates the total sales for each product and category.\n",
        "We group the results by both product_id and product_category.\n",
        "The result includes columns for product_id, product_category, and total_sales, which represents the total sales within each product category."
      ],
      "metadata": {
        "id": "fJABDyNbFusf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example 4: Calculate the Monthly Sales Growth\n",
        "\n",
        "In this example, we'll calculate the monthly sales growth for each product category. We'll use a CTE to prepare the data for analysis and aggregate functions to calculate growth."
      ],
      "metadata": {
        "id": "jf3Av4uaDL03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultDF = spark.sql(\"\"\"\n",
        "\n",
        "WITH MonthlySales AS(\n",
        "\n",
        "    SELECT\n",
        "        p.product_category,\n",
        "        MONTH(s.sale_date) AS sale_month,\n",
        "        SUM(s.price * s.quantity) AS monthly_sales\n",
        "    FROM sales AS s\n",
        "    INNER JOIN products p ON s.product_id = p.product_id\n",
        "    GROUP BY p.product_category, sale_month\n",
        ")\n",
        "\n",
        "    SELECT\n",
        "        product_category,\n",
        "        sale_month,\n",
        "        monthly_sales,\n",
        "        LAG(monthly_sales, 1 , 0) OVER(PARTITION BY product_category ORDER BY sale_month) AS prev_month_sales,\n",
        "        (monthly_sales - LAG(monthly_sales, 1, 0) OVER (PARTITION BY product_category ORDER BY sale_month)) AS sales_growth\n",
        "\n",
        "    FROM MonthlySales\n",
        "    ORDER BY product_category, sale_month\n",
        "\n",
        "\n",
        "\n",
        "\"\"\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN9Y3HzHB9Lf",
        "outputId": "ee47c159-419b-441c-aa6e-d7bf6f3f4496"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------+-------------+----------------+------------+\n",
            "|product_category|sale_month|monthly_sales|prev_month_sales|sales_growth|\n",
            "+----------------+----------+-------------+----------------+------------+\n",
            "|Clothing        |1         |520.0        |0.0             |520.0       |\n",
            "|Electronics     |1         |1240.0       |0.0             |1240.0      |\n",
            "+----------------+----------+-------------+----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:\n",
        "\n",
        "We use a CTE (Common Table Expression) called MonthlySales to group sales data by product category and month, calculating monthly sales totals.\n",
        "In the main query, we calculate the sales growth by comparing the monthly sales with the previous month's sales using the LAG window function.\n",
        "The result includes columns for product_category, sale_month, monthly_sales, prev_month_sales, and sales_growth."
      ],
      "metadata": {
        "id": "17KonMC3FZFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example 5: Find Top-Selling Products by Category\n",
        "\n",
        "In this example, we'll find the top-selling product within each product category."
      ],
      "metadata": {
        "id": "Crz05cPmEjPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_top_selling_product = spark.sql(\"\"\"\n",
        "\n",
        "  WITH ProductRank AS (\n",
        "\n",
        "    SELECT\n",
        "        p.product_category,\n",
        "        s.product_id,\n",
        "        SUM(s.price * s.quantity) AS total_sales,\n",
        "        RANK() OVER (PARTITION BY p.product_category ORDER BY SUM(s.price * s.quantity) DESC) AS rank\n",
        "\n",
        "    FROM sales s\n",
        "    INNER JOIN products p ON s.product_id = p.product_id\n",
        "    GROUP BY p.product_category, s.product_id\n",
        "  )\n",
        "\n",
        "  SELECT\n",
        "      product_category,\n",
        "      product_id,\n",
        "      total_sales\n",
        "  FROM ProductRank\n",
        "  WHERE rank = 1\n",
        "\n",
        "\"\"\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6HtK_9SEnFJ",
        "outputId": "5af43883-b51e-49e3-e458-76d8cb689ac8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------+-----------+\n",
            "|product_category|product_id|total_sales|\n",
            "+----------------+----------+-----------+\n",
            "|Clothing        |102       |360.0      |\n",
            "|Electronics     |101       |690.0      |\n",
            "+----------------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation:\n",
        "\n",
        "We use a CTE called ProductRank to calculate the total sales for each product within each product category and assign a rank based on sales.\n",
        "In the main query, we filter the results to include only the products with a rank of 1, indicating the top-selling product in each category.\n",
        "The result includes columns for product_category, product_id, and total_sales."
      ],
      "metadata": {
        "id": "MTDaRpgMFWk8"
      }
    }
  ]
}